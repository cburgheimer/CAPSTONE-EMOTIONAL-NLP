{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c336b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cburgheimer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cburgheimer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from models.cnn_model import *\n",
    "from models.rnn_model import *\n",
    "from models.bert_model import *\n",
    "from models.GPT_2_model import *\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1930a7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6b7683ed7282b534\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6b7683ed7282b534\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6df33c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data_with_labels/Data_Sentences_W_ Labels.csv',header=0, usecols = ['Sentence', 'Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c56d8a13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BERT_MultiLabel_MultiClass\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 25,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1 (Gl  (None, 768)         0           ['bert[0][0]']                   \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " pooled_outputs (Dropout)       (None, 768)          0           ['global_average_pooling1d_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Anticipation (Dense)           (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Anger (Dense)                  (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Disgust (Dense)                (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Fear (Dense)                   (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Joy (Dense)                    (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Sadness (Dense)                (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Surprise (Dense)               (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Trust (Dense)                  (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,488,392\n",
      "Trainable params: 109,488,392\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "32/32 [==============================] - 16s 497ms/step - loss: 3.5983 - Anticipation_loss: 0.5685 - Anger_loss: 0.3724 - Disgust_loss: 0.3373 - Fear_loss: 0.4148 - Joy_loss: 0.4871 - Sadness_loss: 0.4666 - Surprise_loss: 0.4270 - Trust_loss: 0.5245 - Anticipation_binary_accuracy: 0.7475 - Anger_binary_accuracy: 0.8772 - Disgust_binary_accuracy: 0.8952 - Fear_binary_accuracy: 0.8553 - Joy_binary_accuracy: 0.8104 - Sadness_binary_accuracy: 0.8234 - Surprise_binary_accuracy: 0.8493 - Trust_binary_accuracy: 0.7824\n",
      "Average Loss:  0.44978436827659607 \n",
      "\n",
      "Anticipation Loss:  0.5684762597084045 \n",
      "\n",
      "Anticipation Accuracy:  0.7475050091743469 \n",
      "\n",
      "Anger Loss:  0.37242332100868225 \n",
      "\n",
      "Anger Accuracy:  0.8772454857826233 \n",
      "\n",
      "Disgust Loss:  0.3372635543346405 \n",
      "\n",
      "Disgust Accuracy:  0.8952096104621887 \n",
      "\n",
      "Fear Loss:  0.4148161709308624 \n",
      "\n",
      "Fear Accuracy:  0.8552893996238708 \n",
      "\n",
      "Joy Loss:  0.4871421158313751 \n",
      "\n",
      "Joy Accuracy:  0.8103792667388916 \n",
      "\n",
      "Sadness Loss:  0.4666081964969635 \n",
      "\n",
      "Sadness Accuracy:  0.8233532905578613 \n",
      "\n",
      "Surprise Loss:  0.4270268380641937 \n",
      "\n",
      "Surprise Accuracy:  0.8493013978004456 \n",
      "\n",
      "Trust Loss:  0.5245186686515808 \n",
      "\n",
      "Trust Accuracy:  0.7824351191520691 \n",
      "\n",
      "Average Accuracy: 0.8300898224115372\n"
     ]
    }
   ],
   "source": [
    "bert_model, bert_history = run_BERT(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "560279f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bert_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bert_model\\assets\n",
      "C:\\Anaconda3\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "bert_model.save('bert_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be5bb54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2Model.\n",
      "\n",
      "All the layers of TFGPT2Model were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GPT2_MultiLabel_MultiClass\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " tfgpt2_model (TFGPT2Model)     TFBaseModelOutputWi  124439808   ['input_ids[0][0]',              \n",
      "                                thPast(last_hidden_               'attention_mask[0][0]']         \n",
      "                                state=(None, 25, 76                                               \n",
      "                                8),                                                               \n",
      "                                 past_key_values=((                                               \n",
      "                                2, None, 12, 25, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64)),                                                             \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None)                                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 768)         0           ['tfgpt2_model[0][0]']           \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " pooled_outputs (Dropout)       (None, 768)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " Anticipation (Dense)           (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Anger (Dense)                  (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Disgust (Dense)                (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Fear (Dense)                   (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Joy (Dense)                    (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Sadness (Dense)                (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Surprise (Dense)               (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Trust (Dense)                  (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 124,445,960\n",
      "Trainable params: 124,445,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "32/32 [==============================] - 16s 492ms/step - loss: 3.4882 - Anticipation_loss: 0.5739 - Anger_loss: 0.3604 - Disgust_loss: 0.3433 - Fear_loss: 0.3962 - Joy_loss: 0.4085 - Sadness_loss: 0.4546 - Surprise_loss: 0.4229 - Trust_loss: 0.5283 - Anticipation_binary_accuracy: 0.7475 - Anger_binary_accuracy: 0.8772 - Disgust_binary_accuracy: 0.8882 - Fear_binary_accuracy: 0.8553 - Joy_binary_accuracy: 0.8363 - Sadness_binary_accuracy: 0.8214 - Surprise_binary_accuracy: 0.8493 - Trust_binary_accuracy: 0.7824\n",
      "Average Loss:  0.4360232651233673 \n",
      "\n",
      "Anticipation Loss:  0.5739348530769348 \n",
      "\n",
      "Anticipation Accuracy:  0.7475050091743469 \n",
      "\n",
      "Anger Loss:  0.3604315221309662 \n",
      "\n",
      "Anger Accuracy:  0.8772454857826233 \n",
      "\n",
      "Disgust Loss:  0.34329304099082947 \n",
      "\n",
      "Disgust Accuracy:  0.8882235288619995 \n",
      "\n",
      "Fear Loss:  0.3962344527244568 \n",
      "\n",
      "Fear Accuracy:  0.8552893996238708 \n",
      "\n",
      "Joy Loss:  0.40848663449287415 \n",
      "\n",
      "Joy Accuracy:  0.8363273739814758 \n",
      "\n",
      "Sadness Loss:  0.45459219813346863 \n",
      "\n",
      "Sadness Accuracy:  0.8213573098182678 \n",
      "\n",
      "Surprise Loss:  0.4229089915752411 \n",
      "\n",
      "Surprise Accuracy:  0.8493013978004456 \n",
      "\n",
      "Trust Loss:  0.5283047556877136 \n",
      "\n",
      "Trust Accuracy:  0.7824351191520691 \n",
      "\n",
      "Average Accuracy: 0.8322105780243874\n"
     ]
    }
   ],
   "source": [
    "gpt_model, gpt_history = run_GPT(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7830a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as wte_layer_call_fn, wte_layer_call_and_return_conditional_losses, dropout_layer_call_fn, dropout_layer_call_and_return_conditional_losses, ln_f_layer_call_fn while saving (showing 5 of 735). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: GPT2_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: GPT2_model\\assets\n"
     ]
    }
   ],
   "source": [
    "gpt_model.save('GPT2_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b864223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cburgheimer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cburgheimer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\cburgheimer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cburgheimer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from dataset_cleaning import *\n",
    "label_dict = {'Anticipation':0,'Anger':1, 'Disgust':2,'Fear':3, 'Joy':4, 'Sadness':5, 'Surprise':6, 'Trust':7}\n",
    "tokenized_data, tokenized_labels, tokenizer, max_len = embed_tokenize_data(dataset)\n",
    "labels = label_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e497004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 25, 64)       24487232    ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 25, 1024)     3348480     ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 12, 1024)     0           ['gru[0][0]']                    \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 12, 1024)     0           ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 12, 1024)     8392704     ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 768)          5508096     ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 768)          0           ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " Anticipation (Dense)           (None, 1)            769         ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " Anger (Dense)                  (None, 1)            769         ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " Disgust (Dense)                (None, 1)            769         ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " Fear (Dense)                   (None, 1)            769         ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " Joy (Dense)                    (None, 1)            769         ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " Sadness (Dense)                (None, 1)            769         ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " Surprise (Dense)               (None, 1)            769         ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " Trust (Dense)                  (None, 1)            769         ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 41,742,664\n",
      "Trainable params: 41,742,664\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "32/32 [==============================] - 6s 199ms/step - loss: 3.5937 - Anticipation_loss: 0.5674 - Anger_loss: 0.3726 - Disgust_loss: 0.3381 - Fear_loss: 0.4138 - Joy_loss: 0.4863 - Sadness_loss: 0.4666 - Surprise_loss: 0.4251 - Trust_loss: 0.5239 - Anticipation_binary_accuracy: 0.7475 - Anger_binary_accuracy: 0.8772 - Disgust_binary_accuracy: 0.8952 - Fear_binary_accuracy: 0.8553 - Joy_binary_accuracy: 0.8104 - Sadness_binary_accuracy: 0.8234 - Surprise_binary_accuracy: 0.8493 - Trust_binary_accuracy: 0.7824\n",
      "Average Loss:  0.44920942187309265 \n",
      "\n",
      "Anticipation Loss:  0.5673713684082031 \n",
      "\n",
      "Anticipation Accuracy:  0.7475050091743469 \n",
      "\n",
      "Anger Loss:  0.3725547194480896 \n",
      "\n",
      "Anger Accuracy:  0.8772454857826233 \n",
      "\n",
      "Disgust Loss:  0.33811917901039124 \n",
      "\n",
      "Disgust Accuracy:  0.8952096104621887 \n",
      "\n",
      "Fear Loss:  0.413776159286499 \n",
      "\n",
      "Fear Accuracy:  0.8552893996238708 \n",
      "\n",
      "Joy Loss:  0.48633047938346863 \n",
      "\n",
      "Joy Accuracy:  0.8103792667388916 \n",
      "\n",
      "Sadness Loss:  0.4665917158126831 \n",
      "\n",
      "Sadness Accuracy:  0.8233532905578613 \n",
      "\n",
      "Surprise Loss:  0.42506593465805054 \n",
      "\n",
      "Surprise Accuracy:  0.8493013978004456 \n",
      "\n",
      "Trust Loss:  0.5238657593727112 \n",
      "\n",
      "Trust Accuracy:  0.7824351191520691 \n",
      "\n",
      "Average Accuracy: 0.8300898224115372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: rnn_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: rnn_model\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x000001E545CFAD60> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001E5373403A0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001E53782D2E0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "rnn_model, rnn_history = run_rnn_model(tokenized_data, tokenized_labels, tokenizer, max_len, labels)\n",
    "rnn_model.save('rnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "951b621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " main_input (InputLayer)        [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 25, 64)       24487232    ['main_input[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 14, 768)      590592      ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 768)         0           ['conv1d[0][0]']                 \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 768)          0           ['global_max_pooling1d[0][0]']   \n",
      "                                                                                                  \n",
      " Anticipation (Dense)           (None, 1)            769         ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " Anger (Dense)                  (None, 1)            769         ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " Disgust (Dense)                (None, 1)            769         ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " Fear (Dense)                   (None, 1)            769         ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " Joy (Dense)                    (None, 1)            769         ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " Sadness (Dense)                (None, 1)            769         ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " Surprise (Dense)               (None, 1)            769         ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " Trust (Dense)                  (None, 1)            769         ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25,083,976\n",
      "Trainable params: 25,083,976\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 3.5889 - Anticipation_loss: 0.5672 - Anger_loss: 0.3712 - Disgust_loss: 0.3391 - Fear_loss: 0.4130 - Joy_loss: 0.4856 - Sadness_loss: 0.4680 - Surprise_loss: 0.4244 - Trust_loss: 0.5205 - Anticipation_binary_accuracy: 0.7475 - Anger_binary_accuracy: 0.8772 - Disgust_binary_accuracy: 0.8952 - Fear_binary_accuracy: 0.8553 - Joy_binary_accuracy: 0.8104 - Sadness_binary_accuracy: 0.8234 - Surprise_binary_accuracy: 0.8493 - Trust_binary_accuracy: 0.7824\n",
      "Average Loss:  0.4486173093318939 \n",
      "\n",
      "Anticipation Loss:  0.5672101378440857 \n",
      "\n",
      "Anticipation Accuracy:  0.7475050091743469 \n",
      "\n",
      "Anger Loss:  0.37121835350990295 \n",
      "\n",
      "Anger Accuracy:  0.8772454857826233 \n",
      "\n",
      "Disgust Loss:  0.33911269903182983 \n",
      "\n",
      "Disgust Accuracy:  0.8952096104621887 \n",
      "\n",
      "Fear Loss:  0.41301846504211426 \n",
      "\n",
      "Fear Accuracy:  0.8552893996238708 \n",
      "\n",
      "Joy Loss:  0.48556235432624817 \n",
      "\n",
      "Joy Accuracy:  0.8103792667388916 \n",
      "\n",
      "Sadness Loss:  0.4679635465145111 \n",
      "\n",
      "Sadness Accuracy:  0.8233532905578613 \n",
      "\n",
      "Surprise Loss:  0.4243605136871338 \n",
      "\n",
      "Surprise Accuracy:  0.8493013978004456 \n",
      "\n",
      "Trust Loss:  0.5204931497573853 \n",
      "\n",
      "Trust Accuracy:  0.7824351191520691 \n",
      "\n",
      "Average Accuracy: 0.8300898224115372\n",
      "INFO:tensorflow:Assets written to: cnn_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn_model\\assets\n"
     ]
    }
   ],
   "source": [
    "cnn_model, cnn_history = run_cnn_model(tokenized_data, tokenized_labels, tokenizer, max_len, labels)\n",
    "cnn_model.save('cnn_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5878edfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
