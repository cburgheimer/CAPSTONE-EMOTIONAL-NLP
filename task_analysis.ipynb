{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c336b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from models.cnn_model import *\n",
    "from models.rnn_model import *\n",
    "from models.bert_model import *\n",
    "from models.GPT_2_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1930a7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6df33c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data_with_labels/Data_Sentences_W_ Labels.csv',header=0, usecols = ['Sentence', 'Response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c56d8a13",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13100), started 0:03:46 ago. (Use '!kill 13100' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c3f72f9b23710380\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c3f72f9b23710380\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BERT_MultiLabel_MultiClass\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 25,                                                \n",
      "                                768),                                                             \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 768)         0           ['bert[0][0]']                   \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " pooled_outputs (Dropout)       (None, 768)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " Anticipation (Dense)           (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Anger (Dense)                  (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Disgust (Dense)                (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Fear (Dense)                   (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Joy (Dense)                    (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Sadness (Dense)                (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Surprise (Dense)               (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Trust (Dense)                  (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,488,392\n",
      "Trainable params: 109,488,392\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "32/32 [==============================] - 13s 391ms/step - loss: 3.5943 - Anticipation_loss: 0.5675 - Anger_loss: 0.3725 - Disgust_loss: 0.3376 - Fear_loss: 0.4138 - Joy_loss: 0.4866 - Sadness_loss: 0.4669 - Surprise_loss: 0.4256 - Trust_loss: 0.5240 - Anticipation_binary_accuracy: 0.7475 - Anger_binary_accuracy: 0.8772 - Disgust_binary_accuracy: 0.8952 - Fear_binary_accuracy: 0.8553 - Joy_binary_accuracy: 0.8104 - Sadness_binary_accuracy: 0.8234 - Surprise_binary_accuracy: 0.8493 - Trust_binary_accuracy: 0.7824\n",
      "Average Loss:  0.4492935240268707 \n",
      "\n",
      "Anticipation Loss:  0.5674653053283691 \n",
      "\n",
      "Anticipation Accuracy:  0.7475050091743469 \n",
      "\n",
      "Anger Loss:  0.37246087193489075 \n",
      "\n",
      "Anger Accuracy:  0.8772454857826233 \n",
      "\n",
      "Disgust Loss:  0.3375556766986847 \n",
      "\n",
      "Disgust Accuracy:  0.8952096104621887 \n",
      "\n",
      "Fear Loss:  0.4137943685054779 \n",
      "\n",
      "Fear Accuracy:  0.8552893996238708 \n",
      "\n",
      "Joy Loss:  0.48663172125816345 \n",
      "\n",
      "Joy Accuracy:  0.8103792667388916 \n",
      "\n",
      "Sadness Loss:  0.46689319610595703 \n",
      "\n",
      "Sadness Accuracy:  0.8233532905578613 \n",
      "\n",
      "Surprise Loss:  0.4255538582801819 \n",
      "\n",
      "Surprise Accuracy:  0.8493013978004456 \n",
      "\n",
      "Trust Loss:  0.5239934325218201 \n",
      "\n",
      "Trust Accuracy:  0.7824351191520691 \n",
      "\n",
      "Average Accuracy: 0.8300898224115372\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir bert_logs\n",
    "bert_model, history = run_BERT(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "560279f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bert_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: bert_model\\assets\n",
      "C:\\Anaconda3\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:112: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n"
     ]
    }
   ],
   "source": [
    "bert_model.save('bert_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0be5bb54",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 13608), started 0:05:14 ago. (Use '!kill 13608' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-38bdbff936945727\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-38bdbff936945727\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2Model.\n",
      "\n",
      "All the layers of TFGPT2Model were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"GPT2_MultiLabel_MultiClass\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 25)]         0           []                               \n",
      "                                                                                                  \n",
      " tfgpt2_model_2 (TFGPT2Model)   TFBaseModelOutputWi  124439808   ['input_ids[0][0]',              \n",
      "                                thPast(last_hidden_               'attention_mask[0][0]']         \n",
      "                                state=(None, 25, 76                                               \n",
      "                                8),                                                               \n",
      "                                 past_key_values=((                                               \n",
      "                                2, None, 12, 25, 64                                               \n",
      "                                ),                                                                \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64),                                                              \n",
      "                                 (2, None, 12, 25,                                                \n",
      "                                64)),                                                             \n",
      "                                 hidden_states=None                                               \n",
      "                                , attentions=None)                                                \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2 (Gl  (None, 768)         0           ['tfgpt2_model_2[0][0]']         \n",
      " obalAveragePooling1D)                                                                            \n",
      "                                                                                                  \n",
      " pooled_outputs (Dropout)       (None, 768)          0           ['global_average_pooling1d_2[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " Anticipation (Dense)           (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Anger (Dense)                  (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Disgust (Dense)                (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Fear (Dense)                   (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Joy (Dense)                    (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Sadness (Dense)                (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Surprise (Dense)               (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      " Trust (Dense)                  (None, 1)            769         ['pooled_outputs[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 124,445,960\n",
      "Trainable params: 124,445,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... \n",
      "32/32 [==============================] - 14s 434ms/step - loss: 3.5224 - Anticipation_loss: 0.5628 - Anger_loss: 0.3746 - Disgust_loss: 0.3387 - Fear_loss: 0.3987 - Joy_loss: 0.4838 - Sadness_loss: 0.4482 - Surprise_loss: 0.4141 - Trust_loss: 0.5015 - Anticipation_binary_accuracy: 0.7475 - Anger_binary_accuracy: 0.8772 - Disgust_binary_accuracy: 0.8952 - Fear_binary_accuracy: 0.8533 - Joy_binary_accuracy: 0.8104 - Sadness_binary_accuracy: 0.8094 - Surprise_binary_accuracy: 0.8493 - Trust_binary_accuracy: 0.7824\n",
      "Average Loss:  0.4402976632118225 \n",
      "\n",
      "Anticipation Loss:  0.5627881288528442 \n",
      "\n",
      "Anticipation Accuracy:  0.7475050091743469 \n",
      "\n",
      "Anger Loss:  0.374627947807312 \n",
      "\n",
      "Anger Accuracy:  0.8772454857826233 \n",
      "\n",
      "Disgust Loss:  0.33868885040283203 \n",
      "\n",
      "Disgust Accuracy:  0.8952096104621887 \n",
      "\n",
      "Fear Loss:  0.3986887037754059 \n",
      "\n",
      "Fear Accuracy:  0.8532934188842773 \n",
      "\n",
      "Joy Loss:  0.48378801345825195 \n",
      "\n",
      "Joy Accuracy:  0.8103792667388916 \n",
      "\n",
      "Sadness Loss:  0.4482211470603943 \n",
      "\n",
      "Sadness Accuracy:  0.8093812465667725 \n",
      "\n",
      "Surprise Loss:  0.4140941798686981 \n",
      "\n",
      "Surprise Accuracy:  0.8493013978004456 \n",
      "\n",
      "Trust Loss:  0.5014841556549072 \n",
      "\n",
      "Trust Accuracy:  0.7824351191520691 \n",
      "\n",
      "Average Accuracy: 0.8280938193202019\n"
     ]
    }
   ],
   "source": [
    "GPT_model, gpt_history = run_GPT(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7830a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as wte_layer_call_fn, wte_layer_call_and_return_conditional_losses, dropout_74_layer_call_fn, dropout_74_layer_call_and_return_conditional_losses, ln_f_layer_call_fn while saving (showing 5 of 735). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: GPT2_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: GPT2_model\\assets\n"
     ]
    }
   ],
   "source": [
    "GPT_model.save('GPT2_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5878edfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
